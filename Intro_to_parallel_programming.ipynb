{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Programming in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern CPUs have multiple physical cores on a single chip. Four, six, and eight physical cores are becoming extremely common on consumer CPUs. The current generation of Intel Xeon CPUs which are found in enterprise-level hardware can have up to 28 physical cores per CPU.\n",
    "\n",
    "Additionally, if the CPU supports hyperthreading, each core can handle two tasks simultaneously. Therefore a 6-core CPU with hyperthreading can be viewed as having 12-virtual cores which can all be utilized independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://5.imimg.com/data5/KE/ME/MY-12042782/intel-core-processor-500x500.jpg\" width=250>\n",
    "<center>Intel Core i7 - 8700k CPU with 6 physical cores</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python, be default, will only ever utilize a single CPU core at a time. All instructions in your code are run one at a time, in serial, on one core of your CPU. This leaves all of the other cores sitting there doing nothing (well... not nothing, they are handling other stuff on your system, but not your code, and thats all we really care about).\n",
    "\n",
    "<img src=\"https://images.anandtech.com/doci/13446/cpu0-12.png\" width=300></img>\n",
    "<center style=\"font-style: italic\">Human demonstration of running standard python code on a multi-CPU/core system</center><br>\n",
    "\n",
    "The illustration below shows a simple example of generating 4 random strings. In serial (right), the `rand_string()` function is called 4 times in a row to generate 4 random strings. This could also be accomplished in parallel (left) by having 4 CPU cores each call `rand_string()` once and all at the same time. Theoretically, this would speed up computation 4X.\n",
    "\n",
    "<sub>note: in this simple example, computation would not be sped up at all. It would more than likely take longer to execute this in parallel using python. That is because there is some overhead that occurs when launching parallel tasks. However, if your computational load is large enough, this would accelerate your computation 4X*</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/blog/2014/multiprocessing_intro/multiprocessing_scheme.png\" width=600>\n",
    "<center></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python contains several modules in the standard library that allow you to perform tasks in parallel. However it is not quite as simple as just importing a library and saying go. You have to think about how your code operates a little differently. And of course, not all tasks can be parallelized.\n",
    "\n",
    "At a very high level, Python allows you to handle parallelism in two different ways:\n",
    "\n",
    "1. Threads - Multithreading\n",
    "2. Processes - Multiprocessing\n",
    "\n",
    "Each has it's own unique pros and cons and appropriate use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Threads vs Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides both a [threading](https://docs.python.org/3/library/threading.html) and a [processing](https://docs.python.org/3/library/multiprocessing.html?highlight=multiprocessing#module-multiprocessing) module to handle tasks simultaneously (concurrency).\n",
    "\n",
    "From a high level, these models appear almost identical and seem to provide identical function. You could use them both side by side and from the keyboard it would appear they both performed exactly the same. However, how these modules are functioning differently under-the-hood are extremely important to understand to make sure your code is executing as efficiently as possible.\n",
    "\n",
    "This section will cover a few main differences between the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences in CPU usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part comes first because it is probably by far the most imporant. **Multithreading** in python will ONLY ever use **1 CPU core**. You can create and excute as many threads as you want within your program, but you will never use more than 1 CPU core at a time.\n",
    "\n",
    "Why is this? Well it is because Python multithreadding is not actually executing code in parallel. It just looks and acts like it. What is actually happeneing, is the CPU is quickly switching between each of the threads. This has to happen because of Python's infamous **Global Interpreter Lock (GIL)**. You can read all about it [here](https://wiki.python.org/moin/GlobalInterpreterLock) and [here](https://docs.python.org/3/c-api/init.html#thread-state-and-the-global-interpreter-lock). In short the GIL allows only one thread to execute **python code** at a time. However, the GIL is released during input/output (I/O) operations (important to note for later) and can released by packages executing C-code directly (e.g. numpy).\n",
    "\n",
    "<img src=\"https://hackernoon.com/photos/ZbqyG0GzLmVkwsYNyBRB9kTk5DR2-83212cm\" width=250>\n",
    "<center style=\"font-style: italic\">Python concurency using threads</center><br>\n",
    "<img src=\"https://hackernoon.com/photos/ZbqyG0GzLmVkwsYNyBRB9kTk5DR2-gwnd122h\" width=250>\n",
    "<center style=\"font-style: italic\">Python concurency using processes</center>\n",
    "\n",
    "That standard implementation of Python is written in C (CPython) and was first released in 1990 before the era of modern multi-core CPUs. Additionally, the memory management of all modules utilized CPython are not necessarily thread-safe so the GIL was created to ensure thread-safety in the Python language as a whole. The GIL was found to be the most performant solution at the time (and still today) in the case of single-theaded operation, which is the standard use of Python then and now.\n",
    "\n",
    "But why is the GIL still around 30 years later? Well, there have been many proposals to remove the GIL from Python contributors, but nobody has found a good solution to it yet.\n",
    "\n",
    "The solution for true parallel processing in Python comes from the **multiprocessing** library. Using this library gets around the GIL by spawning an entirely independent system process with its own Python interpreter. With this comes overhead; it takes time to spawn child processes and memory-spaces must be **copied for each child process**. \n",
    "\n",
    "This means not only is multiprocessing limited by the number of CPUs you have. You must also have enough memory to hold replicates of the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences in memory management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to a discussion of the second important difference between Python thread and processes: How they utilize memory.\n",
    "\n",
    "Threads all share common memory with their parent process. This is good in that: They do not need to create a copy of object for each thread, and they can easily communicate with each other through shared data. **But caution:** it is very easy to create race conditions where two threads try to access or modify the same memory object simultaneously.\n",
    "\n",
    "Processes each contain a copy of the parnets memory-space. This means there is no worry about one process modifying a piece of memory while the other is trying to read it. But it also makes it more difficult to share data bewteen processes.\n",
    "\n",
    "<img src=\"https://uploads.toptal.io/blog/image/126087/toptal-blog-image-1526311066247-4ce28d0e2a6878d80c5374d2c53e8aff.png\" width=350>\n",
    "<center style=\"font-style: italic\">Python threads use a shared memory space</center><br>\n",
    "<img src=\"https://uploads.toptal.io/blog/image/126088/toptal-blog-image-1526311071925-a4dc10cda4cf6b88a7f11fd5d4c76f9a.png\" width=350>\n",
    "<center style=\"font-style: italic\">Python processes get independent copies of the parent memory space</center>\n",
    "\n",
    "However, Python does provide some modules out-of-the-box which provide thread-safe mechanisms to share data between threads and processes. The [Queue](https://docs.python.org/3/library/queue.html). Which will be demonstrated in the examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should I use a Thread or a Process\n",
    "\n",
    "The easiest way to determine which method you should use is to look at your program and decide: is my problem a CPU-bound problem or an I/O-bound problem. In other words does my program spend most of its time doing computations or does it spend most of its time waiting for I/O (reading/writing to disk, communicating over the network, etc). \n",
    "\n",
    "If your program is I/O-bound, using threads will speed up the program, because I/O happens outside of the GIL.\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/IOBound.4810a888b457.png\" width=450>\n",
    "<center style=\"font-style: italic\">An I/O bound program</center><br>\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/Threading.3eef48da829e.png\" width=450>\n",
    "<center style=\"font-style: italic\">Speeding up an I/O-bound problem using threads</center><br>\n",
    "\n",
    "If you program is CPU-bound. Threads will offer no increase in speed, because remember, the CPU is just switching back and forth between threads. However, using Processe you can speed up CPU-bound programs dramatically.\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/CPUBound.d2d32cb2626c.png\" width=450>\n",
    "<center style=\"font-style: italic\">An CPU bound program</center><br>\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/CPUMP.69c1a7fad9c4.png\" width=450>\n",
    "<center style=\"font-style: italic\">Speeding up an CPU-bound problem using Processes</center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Examples\n",
    "\n",
    "Below are some simple examples on how to utilize the discussed modules in Python. These are for demonstration and reference purposes only. They are by no means intended to be an exhaustive tutorial on any of this modules.\n",
    "\n",
    "<sub>Note: Python offers some modules to abstract a way some of what we are doing in the examples below, [Pool](https://docs.python.org/3/library/multiprocessing.html?highlight=pool#multiprocessing.pool.Pool) for example. But these are a little buggy when running in Jupyter notebooks, and don't allow you to appreciate what they are actually doing.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue, Event\n",
    "from queue import Empty\n",
    "from threading import Thread\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O speed-up using Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a csv with 10M rows\n",
    "temp = tempfile.NamedTemporaryFile(\"wt\")\n",
    "for i in range(10000000):\n",
    "    temp.write(\"line,data,{}\\n\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>data</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>line</td>\n",
       "      <td>data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>line</td>\n",
       "      <td>data</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>line</td>\n",
       "      <td>data</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>line</td>\n",
       "      <td>data</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>line</td>\n",
       "      <td>data</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line  data  0\n",
       "0  line  data  1\n",
       "1  line  data  2\n",
       "2  line  data  3\n",
       "3  line  data  4\n",
       "4  line  data  5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(temp.name).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.24 s ± 17.9 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r3\n",
    "# Simulate reading in 3 large dataframes in a row\n",
    "for i in range(3):\n",
    "    pd.read_csv(temp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read in a single dataframe\n",
    "def read_df(filepath):\n",
    "    pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.18 s ± 51.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r3\n",
    "# Use threads to simultaneouly read in the 3 dataframes\n",
    "threads = []\n",
    "for i in range(3):\n",
    "    t = Thread(target=read_df, args=(temp.name,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    \n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the temp file\n",
    "temp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your numbers will vary. By on my laptop I got a 8.4 seconds vs 5.1 seconds. A noticable improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up long running jobs using Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_runtimes = [5,2,4,1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a long running process with a runtime that is variable\n",
    "def long_running_process(process_id: int, task_time: int):\n",
    "    time.sleep(task_time)\n",
    "    print(\"Process id {} - Complete - Task time: {}s\".format(process_id, task_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id 0 - Complete - Task time: 5s\n",
      "Process id 1 - Complete - Task time: 2s\n",
      "Process id 2 - Complete - Task time: 4s\n",
      "Process id 3 - Complete - Task time: 1s\n",
      "Process id 4 - Complete - Task time: 5s\n",
      "17 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "# Running this job 5 times in serial\n",
    "for i, task_time in zip(range(5), fake_runtimes):\n",
    "    long_running_process(i, task_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This job happened one at a time. In full it took about 17 seconds and the tasks get done in order in which they were started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id 3 - Complete - Task time: 1s\n",
      "Process id 1 - Complete - Task time: 2s\n",
      "Process id 2 - Complete - Task time: 4s\n",
      "Process id 0 - Complete - Task time: 5s\n",
      "Process id 4 - Complete - Task time: 5s\n",
      "5.04 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "# Use multiple processes to do all 5 concurently\n",
    "processes = []\n",
    "for i, task_time in zip(range(5), fake_runtimes):\n",
    "    p = Process(target=long_running_process, args=(i, task_time))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This job happened all simultaneously in about 5 seconds. The tasks completed in a different order that which they were started. The shortest jobs completes first, and the longest completes last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a messaging queue with multiple workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a message queue for all workers to listen from\n",
    "task_queue = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event which can be used to control all workers, even if you don't maintain a reference to them\n",
    "event = Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a worker to process jobs from the queue\n",
    "def worker_func(queue: Queue, worker_id: int):\n",
    "    print(\"Working {} starting\".format(worker_id))\n",
    "    while event.is_set():\n",
    "        try:\n",
    "            task = queue.get(timeout=2)\n",
    "            task_id, task_time = task\n",
    "            time.sleep(task_time)\n",
    "            result = \"worker id: {} task id: {} task time: {}s\".format(worker_id, task_id, task_time)\n",
    "            print(result)\n",
    "        except Empty:\n",
    "            continue\n",
    "            \n",
    "    else:\n",
    "        print(\"Worker {} Shutting down...\".format(worker_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working 0 starting\n",
      "Working 1 starting\n",
      "Working 2 starting\n",
      "worker id: 0 task id: 0 task time: 1s\n",
      "worker id: 2 task id: 2 task time: 1s\n",
      "worker id: 0 task id: 3 task time: 2s\n",
      "worker id: 1 task id: 1 task time: 4s\n",
      "worker id: 1 task id: 6 task time: 1s\n",
      "worker id: 2 task id: 4 task time: 4s\n",
      "worker id: 2 task id: 8 task time: 2s\n",
      "worker id: 0 task id: 5 task time: 5s\n",
      "worker id: 0 task id: 10 task time: 1s\n",
      "worker id: 1 task id: 7 task time: 4s\n",
      "worker id: 2 task id: 9 task time: 3s\n",
      "worker id: 0 task id: 11 task time: 2s\n",
      "worker id: 2 task id: 13 task time: 1s\n",
      "worker id: 1 task id: 12 task time: 5s\n",
      "worker id: 0 task id: 14 task time: 4s\n",
      "worker id: 2 task id: 100 task time: 3s\n",
      "worker id: 1 task id: 102 task time: 4s\n",
      "worker id: 0 task id: 101 task time: 6s\n",
      "worker id: 2 task id: 103 task time: 6s\n",
      "worker id: 1 task id: 104 task time: 6s\n",
      "worker id: 0 task id: 105 task time: 5s\n",
      "worker id: 1 task id: 107 task time: 2s\n",
      "worker id: 0 task id: 108 task time: 3s\n",
      "worker id: 2 task id: 106 task time: 6s\n",
      "worker id: 0 task id: 110 task time: 4s\n",
      "worker id: 1 task id: 109 task time: 6s\n",
      "Worker 2 Shutting down...\n",
      "Worker 0 Shutting down...\n",
      "Worker 1 Shutting down...\n"
     ]
    }
   ],
   "source": [
    "# Start 3 workers\n",
    "event.set()\n",
    "workers = []\n",
    "for i in range(3):\n",
    "    w = Process(target=worker_func, args=(task_queue, i), daemon=True)\n",
    "    w.start()\n",
    "    workers.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have workers listening for jobs in the background. Lets give them something to do.\n",
    "for i in range(15):\n",
    "    task = (i, random.randint(1,5))\n",
    "    task_queue.put(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100,111):\n",
    "    task = (i, random.randint(2,6))\n",
    "    task_queue.put(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
